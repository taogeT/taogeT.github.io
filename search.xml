<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[海量数据中快速找到最大的100个]]></title>
      <url>%2F2016%2F12%2F14%2F100-hundreds-million-number%2F</url>
      <content type="text"><![CDATA[问题提出存在五十万个数字，如何快速找到最大(小)的100个。 思路思考线索如下： 普通排序方式，需要同时把数据全部加载到内存排序，由于python性能问题不采用。 采用堆排序(heapq)的方式提升排序速度。 不全部加载，每次取500个数据，取其中最大100个。然后再以每次500个加载比较。 代码(Python)# !/usr/env/bin python # -*- coding: utf-8 -*- import heapq import random if __name__ == &apos;__main__&apos;: sample = [] random.randrange for _ in range(1000): sample += [random.randint(1, 100000) for _ in range(500)] sample = heapq.nlargest(100, sample) print(sample)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速查找两个数组中相同浮点数]]></title>
      <url>%2F2016%2F12%2F09%2Ftwo-array-compare%2F</url>
      <content type="text"><![CDATA[问题提出存在两个浮点数数组A、B，如何能快速查找到： 浮点数x在数组A、B中都存在。(1:1) 数组A存在浮点数y，与数组B中浮点数y1、y2….yn相加值相等。同样也在数组B中作相同查找。(1:N or N:1) 数据特征数组的情况和解决方式要求为： 数组长度不会超过10000，但也不会低于1000。 两数组长度不等。 80%-90%的浮点数是符合1:1的情况。剩下的浮点数中都为1:N组合。 查找时间控制在1s内。 思路思考线索如下： 是否存在通用方法解决三种查找情况？不存在，由全组合公式可知存在的组合数量：2的N次方-1(N为数组长度)。由于数组长度不可采用此方式。 按照先后顺序过滤？先查1:1，再查1:N，最后全组合剩余查找M:N。 1:1怎么查？循环查找不可取，浮点数先对数组正序排序，再按照数组顺序查找相同元素。 1:N怎么查？过滤完1:1元素，数组仍然是正序排列。按顺序选取数组A中元素a，查找数组B中所有小于a的浮点数族为数组b，对b进行全组合后相加，得到结果与a比较。对数组B也采取相同方式。 代码(Python)# !/usr/env/bin python # -*- coding: utf-8 -*- from collections import deque import math def create_mix_group_result(group): result = {} for index in range(int(math.pow(2, len(group) - 1) + 1), int(math.pow(2, len(group)))): binstr = bin(index)[2:] mix_group = [group[binindex] for binindex, binvalue in enumerate(binstr) if binvalue == &apos;1&apos;] result[binstr] = sum(mix_group) return result def find_one_to_one(portalA, portalB): if len(portalA) &lt;= 0 or len(portalB) &lt;= 0: return None, portalA, portalB OneToOne, A_filter, B_filter = [], [], [] A = deque(sorted(portalA)) B = deque(sorted(portalB)) while len(A) &gt; 0 and len(B) &gt; 0: if A[0] == B[0]: OneToOne.append(A[0]) A.popleft() B.popleft() elif A[0] &lt; B[0]: A_filter.append(A[0]) A.popleft() else: B_filter.append(B[0]) B.popleft() else: if len(A) &gt; 0: A_filter.extend(A) if len(B) &gt; 0: B_filter.extend(B) return OneToOne, A_filter, B_filter def find_one_to_many(portalA, portalB): if len(portalA) &lt;= 0 or len(portalB) &lt;= 0: return None, portalA, portalB OneToMany, A_filter, B_filter = [], [], [] A = deque(portalA) B_mix_group = create_mix_group_result(portalB) while len(A) &gt; 0: A_ele = A.popleft() for B_mix_key, B_mix_value in B_mix_group.items(): if A_ele == B_mix_value: newportalB = [] getB = [] for delindex, delstr in enumerate(B_mix_key): if delstr == &apos;1&apos;: getB.append(portalB[delindex]) else: newportalB.append(portalB[delindex]) OneToMany.append((A_ele, getB)) portalB = newportalB B_mix_group = create_mix_group_result(portalB) break else: A_filter.append(A_ele) B = deque(portalB) A_mix_group = create_mix_group_result(A_filter) while len(B) &gt; 0: B_ele = B.popleft() for A_mix_key, A_mix_value in A_mix_group.items(): if B_ele == A_mix_value: newA_filter = [] getA = [] for delindex, delstr in enumerate(A_mix_key): if delstr == &apos;1&apos;: getA.append(A_filter[delindex]) else: newA_filter.append(A_filter[delindex]) OneToMany.append((getA, B_ele)) A_filter = newA_filter A_mix_group = create_mix_group_result(A_filter) break else: B_filter.append(B_ele) return OneToMany, A_filter, B_filter if __name__ == &apos;__main__&apos;: A = [9, 1, 4, 6, 3, 10, 9, 3, 5, 2, 4, 10, 13] B = [3, 10, 2, 9, 6, 6, 1, 1, 4, 8, 3, 5, 8, 12, 2, 2] OneToOne, A_filter, B_filter = find_one_to_one(A, B) print(OneToOne, A_filter, B_filter) OneToMany, A_filter, B_filter = find_one_to_many(A_filter, B_filter) print(OneToMany, A_filter, B_filter)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[尝试使用sklearn自动进行多模型预测并计算权重]]></title>
      <url>%2F2016%2F12%2F01%2Fscikit-learn-about-weight%2F</url>
      <content type="text"><![CDATA[待解决的问题在拥有多个模型的情况下，是否可以通过给多个模型分配权重(weight)，使得加权后的多模型预测结果要好于单模型？ 思路 是否存在通用的多模型weight计算方式？ 如果没有，是否存在其他选取模型的方式？ 如果权重只能人为设置，增加权重提高拟合度的方法是否可行？ 如果权重能自动计算，能否在实际数据训练中增加拟合度？ 解决方向 查找相关论文资料，确认了使用多模型同时计算加权的方式不常见。更多的是对单模型做优化以提高拟合度。简单做法是取所有模型拟合度相加等比放大/缩小到1，放大/缩小系数k作为权重。 sklearn中存在一个分类器VotingClassifier，往这个分类器中添加多个模型，可以根据训练集计算得分(score,拟合度)最高的模型，并以此模型做预测。 人为设置方式不可取，调整者需要很丰富的经验和大量测试时间。故采用决策树的方式，自动调整权重，得到与训练集拟合度最高的结果为合适方案。同时，此方案需要大量的样本数据才能拟合准确，否则会出现过拟合or仅在特定训练集表现优秀的情况。 试验假设存在三个模型A B C，训练集train_set。 简单权重计算训练集拟合得分Sa, Sb, Sc。权重计算为 当存在 Si&lt;=0 时，该模型的权重Wi = 0，不计算结果。 Ssum = Sa，Sb，Sc相加。 权重 Wi = Si / Ssum。 此方式得到的权重，在实际计算中未能有效的提升预测结果的拟合度，表现与使用单模型相差不大，整体上表现略逊于拟合度&gt;0.5的模型。 sklearn分类器将模型放入sklearn分类器进行模拟时发现，分类器选取要求每个模型拟合的训练集在数据清洗组合后都是同维的，才能进行比较。而目前使用的模型：支持向量机(SVR)，隐性时间序列(HiddenPeriod)，需要的训练集是完全不同维度的(SVR：28, HP: 1)。且将来添加其他模型需要训练的维度也大概率是不同于两者。故此方案不可行。 决策树目前由于数据数量和边界条件不明，暂时无法做拟合度测试。待重启 结论以目前的研究和试验看来，权重的方式对拟合度的提升不明显，效率提升不如对单模型进行优化。故权重计算的开发可暂时延后。 另一种思路？不采用权重同时训练所有的模型，而是先取某个模型进行训练，再针对残差使用另一个模型进行训练。这种思路会使得单模型有针对性的处理特定数据训练集，是否能提高拟合度有待检验。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[单元测试(Unit Test)覆盖级别]]></title>
      <url>%2F2016%2F12%2F01%2Funit-test-standard%2F</url>
      <content type="text"><![CDATA[这是我个人从外部文档和工作项目中总结，当开发单元测试时，根据项目级别不同需要达到级别标准。 级别分类 Level1：正常流程可用，函数在输入正确的参数时，会有正确的输出。 Level2：异常流程可抛出逻辑异常，输入参数有误时，不能抛出系统异常，而是用自定义的逻辑异常通知上层调用代码的错误。 Level3：极端情况和边界数据可用，对输入参数的边界情况也要单独测试，确保输出是正确有效。 Level4：所有分支、循环的逻辑走通，不能有任何流程是测试不到。 Level5：输出数据的所有字段验证，对有复杂数据结构的输出，确保每个字段都是正确的。 使用标准一般项目只要做到Level2~3即可。数据量庞大的项目需要做到Level4。高密高危项目需要做到Level5。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Welcome To My Maze!!!]]></title>
      <url>%2F2016%2F11%2F22%2Fself-welcome%2F</url>
      <content type="text"><![CDATA[欢迎来到迷宫 想要我的财宝吗？想要的话可以全部给你，去找吧！我把所有财宝都放在那里！ 这里是存放个人技术文章的小仓库，也会收录一些其他站点文章作备份(字典)。浏览文章中偶尔会遇到奇怪的东西，不感兴趣的话请略过。想与作者联系的请参考左侧栏选择适合你的联系方式，欢迎大家来找茬！ 近期任务：Angular 1.x 学习了解]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[直播平台爬虫项目介绍]]></title>
      <url>%2F2016%2F11%2F22%2Fabout-living-mining%2F</url>
      <content type="text"><![CDATA[项目介绍项目实现爬虫、数据分析，主要是爬取直播(斗鱼、Bilibili)收集数据，后续开发分析功能。代码采用GPL v2协议，开源发布在 Github上。项目部署在站点：http://www.zhengwentao.com。项目是在个人兴趣下用业余时间写的，技术还欠缺火候。使用中有bug或更新建议，欢迎提issue。 功能 爬取指定直播站点的频道、房间信息，记录到数据库。 WEB显示爬取内容，以及根据人气值的排名情况。 通过OAuth2可注册用户(支持：github)。 登陆后可根据关键字搜索房间。 根据记录的房间人气值历史信息，预测未来人气值变化趋势(开发中)。 开发历史v2.0(master分支开发) 运行中采用框架： Web服务：Flask(web框架) + Vuejs(页面模板) + Bootstrap(样式)爬虫：Scrapy(爬虫工厂) + Redis(管道) + Crontab(定时任务) 爬取站点：斗鱼 bilibili v1.0(2016-08-15开发完毕)采用框架： Web服务：Flask(web框架) + Jinjia2(页面模板) + Bootstrap(样式)爬虫：Requests(生产请求) + Gevent(异步) + Celery(定时任务) 爬取站点：斗鱼 熊猫 战旗 bilibili 升级原因：采用Gevent协程处理的方式会导致进程长时间占用CPU，由于机器性能不高导致无法处理WEB请求无法访问页面。]]></content>
    </entry>

    
  
  
</search>
